# -*- coding: utf-8 -*-
"""GPT 2_NCHrom .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14qY34-UdJCa-pUBKwD2l6zznoCe9T-gT

# ***Link:*** [NChrom Dataset](https://drive.google.com/drive/folders/1df02EmLoLcrK3sWyOzvpx0oaJopymqry?usp=sharing)
"""

from google.colab import drive
drive.mount('/content/drive')

pip install transformers

pip install transformers[torch]

pip install accelerate -U

import os
from sklearn.model_selection import train_test_split

directory = '/content/drive/My Drive/NChrom' #Change to Local Directory
combined_file = 'combined_data.txt'

with open(combined_file, 'w') as outfile:
    for filename in os.listdir(directory):
        if filename.endswith('.txt'):
            with open(os.path.join(directory, filename), 'r') as infile:
                outfile.write(infile.read() + '\n')

with open(combined_file, 'r') as file:
    lines = file.readlines()

train_lines, test_lines = train_test_split(lines, test_size=0.2)

with open('train_data.txt', 'w') as file:
    file.writelines(train_lines)

with open('test_data.txt', 'w') as file:
    file.writelines(test_lines)

from transformers import GPT2LMHeadModel, GPT2Tokenizer, DataCollatorForLanguageModeling
from transformers import Trainer, TrainingArguments, TextDataset

model = GPT2LMHeadModel.from_pretrained('gpt2-medium')
tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')

train_path = 'train_data.txt'
test_path = 'test_data.txt'

train_dataset = TextDataset(tokenizer=tokenizer, file_path=train_path, block_size=128)
test_dataset = TextDataset(tokenizer=tokenizer, file_path=test_path, block_size=128)

data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)

training_args = TrainingArguments(
    output_dir='./results',
    overwrite_output_dir=True,
    num_train_epochs=5,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    eval_steps=400,
    save_steps=800,
    warmup_steps=500,
    prediction_loss_only=True)

trainer = Trainer(
    model=model,
    args=training_args,
    data_collator=data_collator,
    train_dataset=train_dataset,
    eval_dataset=test_dataset)

trainer.train()

model.save_pretrained('/content/drive/My Drive/gpt2-medium-finetuned-NChrom')

tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')
model = GPT2LMHeadModel.from_pretrained('/content/drive/My Drive/gpt2-medium-finetuned-NChrom')
model.eval()

input_data = "The generatd data summarizes: "
input_ids = tokenizer.encode(input_data, return_tensors='pt')

output = model.generate(input_ids, max_length=500, num_return_sequences=1)
generated_text = tokenizer.decode(output[0], skip_special_tokens=True)

print(generated_text)

import torch
from torch.nn import functional as F

tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')
model = GPT2LMHeadModel.from_pretrained('/content/drive/My Drive/gpt2-medium-finetuned-NChrom')

test_data = ["Chromatography is a process for separating components of a mixture. To get the process started, the mixture is dissolved in a substance called the mobile phase, which carries it through a second substance called the stationary phase.",
             "There are many different ways to use liquid chromatography to separate compounds of interest and the choice of technique usually depends on the physicochemical characteristics of the molecule of interest. The solid phases used for each type of chromatography, known as chromatography media or resins, are highly engineered porous inert supports functionalized with various chemical groups that determine the interactions with the molecules to be separated. ", \
             "Chemistry is the study of substances—that is, elements and compounds—while biology is the study of living things. However, these two branches of science meet in the discipline of biochemistry, which studies the substances in living things and how they change within an organism.",
             "Ion exchange chromatography is a technique for separating compounds based on their net charge",
             "What is gas chromatography? Gas chromatography (GC) is an analytical technique used to separate and detect the chemical components of a sample mixture to determine their presence or absence and/or quantities. These chemical components are usually organic molecules or gases.",
             "Liquid Chromatography Resources. Chromatography is used to separate proteins, nucleic acids, or small molecules in complex mixtures. Liquid chromatography (LC) separates molecules in a liquid mobile phase using a solid stationary phase.",
             "Chromatography was first devised at the University of Kazan by the Italian-born Russian scientist Mikhail Tsvet in 1900."
             "Chromatogram – the visual output of the chromatograph. In the case of an optimal separation, different peaks or patterns on the chromatogram correspond to different components of the separated mixture."
             "Chromatograph – an instrument that enables a sophisticated separation, e.g. gas chromatographic or liquid chromatographic separation."
             "Column chromatography is a separation technique in which the stationary bed is within a tube."
             "Planar chromatography is a separation technique in which the stationary phase is present as or on a plane.",
             "Paper chromatography is a technique that involves placing a small dot or line of sample solution onto a strip of chromatography paper."
             "Thin-layer chromatography (TLC) is a widely employed laboratory technique used to separate different biochemicals on the basis of their relative attractions to the stationary and mobile phases. It is similar to paper chromatography"
             "The word chemistry comes from a modification during the Renaissance of the word alchemy, which referred to an earlier set of practices that encompassed elements of chemistry, metallurgy, philosophy, astrology, astronomy, mysticism, and medicine."
             "The current model of atomic structure is the quantum mechanical model.[12] Traditional chemistry starts with the study of elementary particles, atoms, molecules,[13] substances, metals, crystals and other aggregates of matter."
             "The chemistry laboratory stereotypically uses various forms of laboratory glassware."
             "In chemistry, matter is defined as anything that has rest mass and volume (it takes up space) and is made up of particles."]

log_likelihoods = []
for sentence in test_data:
    inputs = tokenizer.encode(sentence, return_tensors='pt')
    outputs = model(inputs, labels=inputs)
    loss = outputs.loss
    log_likelihoods.append(-loss.item())

avg_log_likelihood = sum(log_likelihoods) / len(log_likelihoods)

perplexity = torch.exp(torch.tensor(avg_log_likelihood))
print("Perplexity:", perplexity)

import matplotlib.pyplot as plt

loss_values = [log['loss'] for log in trainer.state.log_history if 'loss' in log]

plt.plot(loss_values)
plt.title("Training Loss Over Time")
plt.xlabel("Logging Steps")
plt.ylabel("Loss")
plt.show()

question = "What is Green Chemistry?"
input_ids = tokenizer.encode("Question: " + question + " Answer:", return_tensors='pt')

output = model.generate(input_ids, max_length=100, num_return_sequences=1)
answer = tokenizer.decode(output[0], skip_special_tokens=True)

print(answer)

import nltk
from nltk.translate.bleu_score import sentence_bleu
from nltk.tokenize import word_tokenize
nltk.download('punkt')

predicted_answers = ["Green Chemistry is a concept to encourage using energy-saving instruments, decreasing the use of toxic agents or compounds, and producing waste with a minimal amount during analytical procedures. The concept of Green Chemistry is widely recognized in analytical chemistry laboratories. Simple, comprehensive and flexible greenness metrics should be developed and applied to evaluate the impacts of analytical procedures on the environment, human health and human safety. Sixteen greenness metrics just like National Environmental Methods Index (NEMI"]
reference_answers = [["The most important approach developed to address this issue is Green Analytical Chemistry (GAC). GAC is an environmental-friendly approach to analytical chemistry that aims to minimize the negative impact of analytical techniques on the environment and human health. This review provided a comprehensive overview of the history of GAC and the existing greenness assessment metric tools. The various approaches, such as the National Environmental Methods Index (NEMI), Eco-scale Assessment (ESA), Green Analytical Procedure Index (GAPI), and Analytical Greens (AGREE) used to evaluate Green profiles were discussed in detail, and their importance in analytical approaches was examined."]]

predicted_tokens = [word_tokenize(ans) for ans in predicted_answers]
reference_tokens = [[word_tokenize(ans) for ans in refs] for refs in reference_answers]

bleu_scores = [sentence_bleu(refs, pred) for pred, refs in zip(predicted_tokens, reference_tokens)]

average_bleu_score = sum(bleu_scores) / len(bleu_scores)

print("Individual BLEU scores:", bleu_scores)
print("Average BLEU score:", average_bleu_score)

pip install rouge

from rouge import Rouge

predicted_answers = ["Green Chemistry is a concept to encourage using energy-saving instruments, decreasing the use of toxic agents or compounds, and producing waste with a minimal amount during analytical procedures. The concept of Green Chemistry is widely recognized in analytical chemistry laboratories. Simple, comprehensive and flexible greenness metrics should be developed and applied to evaluate the impacts of analytical procedures on the environment, human health and human safety. Sixteen greenness metrics just like National Environmental Methods Index (NEMI"]
reference_answers = [["The most important approach developed to address this issue is Green Analytical Chemistry (GAC). GAC is an environmental-friendly approach to analytical chemistry that aims to minimize the negative impact of analytical techniques on the environment and human health. This review provided a comprehensive overview of the history of GAC and the existing greenness assessment metric tools. The various approaches, such as the National Environmental Methods Index (NEMI), Eco-scale Assessment (ESA), Green Analytical Procedure Index (GAPI), and Analytical Greens (AGREE) used to evaluate Green profiles were discussed in detail, and their importance in analytical approaches was examined."]]

rouge = Rouge()

prepared_reference_answers = [' '.join(refs) for refs in reference_answers]

rouge_scores = [rouge.get_scores(pred, ref) for pred, ref in zip(predicted_answers, prepared_reference_answers)]

for score in rouge_scores:
    print(score)

average_rouge_1 = sum([score[0]['rouge-1']['f'] for score in rouge_scores]) / len(rouge_scores)
average_rouge_2 = sum([score[0]['rouge-2']['f'] for score in rouge_scores]) / len(rouge_scores)
average_rouge_l = sum([score[0]['rouge-l']['f'] for score in rouge_scores]) / len(rouge_scores)

print(f"Average ROUGE-1 Score: {average_rouge_1}")
print(f"Average ROUGE-2 Score: {average_rouge_2}")
print(f"Average ROUGE-L Score: {average_rouge_l}")